{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for sentence classification\n",
    "- References:\n",
    "    - Yoon Kim's [paper link](https://arxiv.org/abs/1408.5882)\n",
    "    - [Reference code](https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/4%20-%20Convolutional%20Sentiment%20Analysis.ipynb) by bentrevett\n",
    "    - Dataset [download](https://github.com/yoonkim/CNN_sentence)\n",
    "- Implementation Points\n",
    "    - OOV token initialization: \n",
    "        - random sampling by uniform distribution with variances of pre-trained word vectors\n",
    "    - Static vs. Non-static (task-specific): \n",
    "        - freeze=True or False\n",
    "    - Multiple channels (two channels): \"each filter is applied to both channels and the results are **added** to calculate $c_i$\"\n",
    "    - Regularization: \"we employ dropout on the penultimate layer with a constraint on $l_2$-norms of the wieght vectors\"\n",
    "        - the penultimate layer **with** a constraint on $l_2$-norms of the wieght vectors:\n",
    "            - Add $l_2$ regularity from **torch.norm()** to loss function!\n",
    "        - dropout means that the element-wise multiplcation operator using **a masking vector of Bernoulli random variables with prob. $p$**:\n",
    "            - **nn.Dropout()**\n",
    "            - \"During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution\"\n",
    "    - Hyperparameters: \n",
    "        - relu function, filter windows of 3,4,5 with 100 feature maps each, dropout rate ($p$) of 0.5, $l_2$ constraint of 3 \n",
    "        - mini-batch size of 50, Adadelta update rule, **dev set is 10% of the training set (Failed!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:20.267330Z",
     "start_time": "2021-01-23T07:52:19.658976Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:20.282852Z",
     "start_time": "2021-01-23T07:52:20.268329Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_seed(seed= 1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "- Note that we should use **open** function instead of **pd.read_table()** when data size is big becuase pandas is slower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:20.298840Z",
     "start_time": "2021-01-23T07:52:20.284853Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 준비 함수 (None -> df)\n",
    "def load_data():\n",
    "    neg_path = r\"C:\\Users\\Simon\\ongoing_projects\\torch_study\\1_CNN\\1_reference_code\\rt-polarity.neg.txt\"\n",
    "    neg_df = pd.read_table(neg_path, header=None, names=['X'], encoding='latin') #'ISO-8859-1' 의 alias\n",
    "    neg_df['y'] = [0] * len(neg_df)\n",
    "\n",
    "    pos_path = r\"C:\\Users\\Simon\\ongoing_projects\\torch_study\\1_CNN\\1_reference_code\\rt-polarity.pos.txt\"\n",
    "    pos_df = pd.read_table(pos_path, header=None, names=['X'], encoding='latin') #'ISO-8859-1' 의 alias\n",
    "    pos_df['y'] = [1] * len(pos_df)\n",
    "\n",
    "    data = pd.concat([neg_df, pos_df], axis=0)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    print(\"# of Loaded Data: {}\".format(data.shape[0]))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:20.330108Z",
     "start_time": "2021-01-23T07:52:20.300835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Loaded Data: 10662\n"
     ]
    }
   ],
   "source": [
    "data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:21.123868Z",
     "start_time": "2021-01-23T07:52:20.331105Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:21.139856Z",
     "start_time": "2021-01-23T07:52:21.124867Z"
    }
   },
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수 (str -> lst)\n",
    "def text_preprocessor(sent):\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    # text preprocessing\n",
    "    sent_str = sent.lower()\n",
    "    sent_str = re.sub('[^a-z]', ' ', sent_str)  # Remove non-alphabetic strings\n",
    "    sent_str = re.sub('  ', ' ', sent_str).strip()  # Remove double white spaces\n",
    "    sent_lst = [word for word in sent_str.split() if word not in stop] # Remove stopwords\n",
    "    return sent_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.206728Z",
     "start_time": "2021-01-23T07:52:21.140854Z"
    }
   },
   "outputs": [],
   "source": [
    "data['X_lst'] = data['X'].map(text_preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.221910Z",
     "start_time": "2021-01-23T07:52:23.208246Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 분리 함수 (df -> [df,df,df])\n",
    "def data_split(df, train_frac= 0.8, val_frac= 0.2, seed=123):\n",
    "    train_df = df.sample(frac= train_frac, random_state= seed)\n",
    "    test_df = df.drop(train_df.index)\n",
    "\n",
    "    val_df = train_df.sample(frac= val_frac, random_state= seed)\n",
    "    train_df = train_df.drop(val_df.index)\n",
    "    \n",
    "    print(\"Train_df shape:\", train_df.shape)\n",
    "    print(\"Val_df shape:\", val_df.shape)\n",
    "    print(\"Test_df shape:\", test_df.shape)\n",
    "\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.252314Z",
     "start_time": "2021-01-23T07:52:23.222866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_df shape: (6824, 3)\n",
      "Val_df shape: (1706, 3)\n",
      "Test_df shape: (2132, 3)\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df, test_df = data_split(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.267998Z",
     "start_time": "2021-01-23T07:52:23.253333Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vocab 만들어주는 함수 ([df,df] -> [dict, dict])\n",
    "def build_vocab(train_df, val_df):\n",
    "    '''train과 valid 데이터만 사용 주의'''\n",
    "    trainWords_lst = [w for w_lst in train_df['X_lst'] for w in w_lst]\n",
    "    ValWords_lst = [w for w_lst in val_df['X_lst'] for w in w_lst]\n",
    "    totalWords_lst = trainWords_lst + ValWords_lst\n",
    "\n",
    "    words_lst = ['<pad>', '<unk>'] + sorted(list(set(totalWords_lst)))\n",
    "\n",
    "    itos = {idx : word for idx, word in enumerate(words_lst)}\n",
    "    stoi = {word : idx for idx, word in enumerate(words_lst)}\n",
    "\n",
    "    print('length of word_set:', len(words_lst))\n",
    "    return itos, stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.299719Z",
     "start_time": "2021-01-23T07:52:23.268705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of word_set: 16278\n"
     ]
    }
   ],
   "source": [
    "itos, stoi = build_vocab(train_df, val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String to Index (Numericalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.315425Z",
     "start_time": "2021-01-23T07:52:23.300717Z"
    }
   },
   "outputs": [],
   "source": [
    "# 문장을 숫자로 표현해주는 함수 (lst -> lst)\n",
    "def token_to_idx(token_lst, stoi):\n",
    "    idx_lst = []\n",
    "    for w in token_lst:\n",
    "        if w in stoi:\n",
    "            idx = stoi[w]\n",
    "        else:\n",
    "            idx = stoi['<unk>']\n",
    "        idx_lst.append(idx)\n",
    "    return idx_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.347340Z",
     "start_time": "2021-01-23T07:52:23.316423Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['X_idx'] = train_df['X_lst'].map(lambda x: token_to_idx(x, stoi))\n",
    "val_df['X_idx'] = val_df['X_lst'].map(lambda x: token_to_idx(x, stoi))\n",
    "test_df['X_idx'] = test_df['X_lst'].map(lambda x: token_to_idx(x, stoi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.363396Z",
     "start_time": "2021-01-23T07:52:23.348338Z"
    }
   },
   "outputs": [],
   "source": [
    "# zero padding을 통해서 시퀀스의 길이를 맞춰주는 함수 ([lst, int, dict] -> lst)\n",
    "def zero_padding(idx_lst, max_len, stoi):\n",
    "    pad_idx = stoi['<pad>']\n",
    "    unk_idx = stoi['<unk>']\n",
    "    \n",
    "    idx_lst = idx_lst[:max_len]\n",
    "    \n",
    "    if len(idx_lst) == max_len:\n",
    "        return idx_lst\n",
    "    else:\n",
    "        padding_len = max_len - len(idx_lst)\n",
    "        padding_list = [pad_idx] * padding_len\n",
    "        idx_lst = idx_lst + padding_list\n",
    "        return idx_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.379297Z",
     "start_time": "2021-01-23T07:52:23.364407Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['X_pad'] = train_df['X_idx'].map(lambda x: zero_padding(x, 10, stoi))\n",
    "val_df['X_pad'] = val_df['X_idx'].map(lambda x: zero_padding(x, 10, stoi))\n",
    "test_df['X_pad'] = test_df['X_idx'].map(lambda x: zero_padding(x, 10, stoi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.395322Z",
     "start_time": "2021-01-23T07:52:23.380295Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x \n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_x = torch.LongTensor(self.x[idx])\n",
    "        target_y = torch.FloatTensor([self.y[idx]]) # 왜 FloatTensor?,torch.FloatTensor([]) 이렇게 넣어줘야하는듯.\n",
    "        return input_x, target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.410466Z",
     "start_time": "2021-01-23T07:52:23.396321Z"
    }
   },
   "outputs": [],
   "source": [
    "# 기존 idx를 제거하기 위해서 list() 사용?\n",
    "trainset = CustomDataset(list(train_df['X_pad']), list(train_df['y']))\n",
    "validset = CustomDataset(list(val_df['X_pad']), list(val_df['y']))\n",
    "testset = CustomDataset(list(test_df['X_pad']), list(test_df['y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.425540Z",
     "start_time": "2021-01-23T07:52:23.411464Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 50\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "validloader = DataLoader(validset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "- In pytorch, CNN wants the batch dimension first!\n",
    "- in_channels: # of channels / out_channels: # of filters / kernel_size: filter size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.440822Z",
     "start_time": "2021-01-23T07:52:23.426572Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.456087Z",
     "start_time": "2021-01-23T07:52:23.441821Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:04:39.895579Z",
     "start_time": "2021-01-23T08:04:39.876654Z"
    }
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings, embedding_dim, freeze, \n",
    "                 n_filters, filter_sizes, \n",
    "                 output_dim, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze= freeze, padding_idx= pad_idx)\n",
    "        \n",
    "        # Note List comprehension\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels= 1,  # 1 channel for TEXT\n",
    "                                              out_channels= n_filters,\n",
    "                                              kernel_size = (fs, embedding_dim))\n",
    "                                    for fs in filter_sizes])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim) # Because of simply \"CONCATENATE\"!\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [batch_size, sent_len]\n",
    "        embedded = self.embedding(text) \n",
    "        # embedded = [batch_size, sent_len, embed_dim]\n",
    "        embedded = embedded.unsqueeze(1) # Insert 1 dimension to represent # of channels like images\n",
    "        \n",
    "        # embedded = [batch_size, 1, sent_len, embed_dim]\n",
    "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # WHY does Squeeze need here?\n",
    "        \n",
    "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        \n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:45.879576Z",
     "start_time": "2021-01-23T08:08:45.860134Z"
    }
   },
   "outputs": [],
   "source": [
    "class Multichannel_CNN(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings, embedding_dim, freeze, \n",
    "                 n_filters, filter_sizes, \n",
    "                 output_dim, dropout, pad_idx):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        self.static_embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze= True, padding_idx= pad_idx)\n",
    "        self.nonstatic_embedding = nn.Embedding.from_pretrained(pretrained_embeddings, freeze= False, padding_idx= pad_idx)\n",
    "        \n",
    "        # Note List comprehension\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(in_channels= 1,  # 1 channel for TEXT\n",
    "                                              out_channels= n_filters,\n",
    "                                              kernel_size = (fs, embedding_dim))\n",
    "                                    for fs in filter_sizes])\n",
    "        \n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim) # Because of simply \"CONCATENATE\"!\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # text = [batch_size, sent_len]\n",
    "        static_embedded = self.static_embedding(text) \n",
    "        nonstatic_embedded = self.nonstatic_embedding(text) \n",
    "        # embedded = [batch_size, sent_len, embed_dim]\n",
    "        static_embedded = static_embedded.unsqueeze(1) # Insert 1 dimension to represent # of channels like images\n",
    "        nonstatic_embedded = nonstatic_embedded.unsqueeze(1)\n",
    "        \n",
    "        # embedded = [batch_size, 1, sent_len, embed_dim]\n",
    "        # WHY does Squeeze need here?\n",
    "        conved = [F.relu(conv(static_embedded)).squeeze(3) + F.relu(conv(nonstatic_embedded)).squeeze(3) for conv in self.convs]\n",
    "        \n",
    "        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n",
    "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
    "        \n",
    "        # pooled_n = [batch_size, n_filters]\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        \n",
    "        # cat = [batch_size, n_filters * len(filter_sizes)]\n",
    "        return self.fc(cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-trained embedding\n",
    "- Load the pretrain Word2Vec model from Google [(Download HERE)](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit) \n",
    "- It might take time since it  contains 300-dimensional vectors for 3 million words and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:23.612956Z",
     "start_time": "2021-01-23T07:52:23.472423Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:38.688783Z",
     "start_time": "2021-01-23T07:52:23.614951Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pretrained_embeddings\n",
    "path = r\"C:\\Users\\Simon\\ongoing_projects\\SSRC_collaboration\\source\\GoogleNews-vectors-negative300.bin\"\n",
    "word_vectors = KeyedVectors.load_word2vec_format(path, binary=True)\n",
    "var_arr = word_vectors.vectors.var(axis=0) # For OOV initialization, 300-dim vectors containing variances of each dimension\n",
    "\n",
    "# Customize pretrained_embeddings \n",
    "pretrained_embeddings = np.zeros((len(stoi), 300)) # <pad>, <unk>은 여기서는 제외시켜야 하나??\n",
    "\n",
    "for i, w in enumerate(list(stoi.keys())):\n",
    "    try:\n",
    "        pretrained_embeddings[i] = word_vectors[w]\n",
    "    except KeyError:\n",
    "        pretrained_embeddings[i] = np.random.uniform(low= var_arr, high= -var_arr)  # Random sampling from Uniform dist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T07:52:38.704256Z",
     "start_time": "2021-01-23T07:52:38.690296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16278, 300)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:52.736592Z",
     "start_time": "2021-01-23T08:08:52.724404Z"
    }
   },
   "outputs": [],
   "source": [
    "# config\n",
    "PRETRAINED_EMB = torch.from_numpy(pretrained_embeddings) # torch.tensor로 전환 주의\n",
    "EMBEDDING_DIM = 300\n",
    "FREEZE = True\n",
    "N_FILTERS = 100\n",
    "FILTER_SIZES = [3,4,5]\n",
    "OUTPUT_DIM = 1\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:52.954347Z",
     "start_time": "2021-01-23T08:08:52.940408Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = CNN(PRETRAINED_EMB, EMBEDDING_DIM, FREEZE, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = Multichannel_CNN(PRETRAINED_EMB, EMBEDDING_DIM, FREEZE, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = model.float()  # Reference: https://github.com/KimythAnly/AGAIN-VC/issues/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:53.520774Z",
     "start_time": "2021-01-23T08:08:53.508168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 5,244,001 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:54.610241Z",
     "start_time": "2021-01-23T08:08:54.595409Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adadelta(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:54.842368Z",
     "start_time": "2021-01-23T08:08:54.836406Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:55.043874Z",
     "start_time": "2021-01-23T08:08:55.035896Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for x, y in iterator:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        predictions = model(x)\n",
    "\n",
    "        # l2-norm regularization\n",
    "        # Reference: https://stackoverflow.com/questions/44641976/in-pytorch-how-to-add-l1-regularizer-to-activations\n",
    "        all_fc_params = torch.cat([x.view(-1) for x in model.fc.parameters()])\n",
    "        l2_regularization = torch.norm(all_fc_params, 3)\n",
    "        \n",
    "        cross_entropy_loss = criterion(predictions, y)\n",
    "        loss = cross_entropy_loss + l2_regularization\n",
    "        acc = binary_accuracy(predictions, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:55.406905Z",
     "start_time": "2021-01-23T08:08:55.396932Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            predictions = model(x)\n",
    "\n",
    "            # l2-norm regularization\n",
    "            all_fc_params = torch.cat([x.view(-1) for x in model.fc.parameters()])\n",
    "            l2_regularization = torch.norm(all_fc_params, 3)\n",
    "\n",
    "            cross_entropy_loss = criterion(predictions, y)\n",
    "            loss = cross_entropy_loss + l2_regularization\n",
    "            acc = binary_accuracy(predictions, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:08:55.729503Z",
     "start_time": "2021-01-23T08:08:55.723519Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:09:27.049088Z",
     "start_time": "2021-01-23T08:08:56.020360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.725 | Train Acc: 54.43%\n",
      "\t Val. Loss: 0.721 |  Val. Acc: 48.17%\n",
      "Epoch: 02 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.706 | Train Acc: 54.69%\n",
      "\t Val. Loss: 0.710 |  Val. Acc: 47.75%\n",
      "Epoch: 03 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.705 | Train Acc: 60.17%\n",
      "\t Val. Loss: 0.704 |  Val. Acc: 71.83%\n",
      "Epoch: 04 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.694 | Train Acc: 68.62%\n",
      "\t Val. Loss: 0.685 |  Val. Acc: 67.45%\n",
      "Epoch: 05 | Epoch Time: 0m 6s\n",
      "\tTrain Loss: 0.659 | Train Acc: 72.94%\n",
      "\t Val. Loss: 0.638 |  Val. Acc: 74.80%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, trainloader, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, validloader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut4-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-23T08:09:27.268525Z",
     "start_time": "2021-01-23T08:09:27.050085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.652 | Test Acc: 73.72%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('tut4-model.pt'))\n",
    "test_loss, test_acc = evaluate(model, testloader, criterion)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.667,
   "position": {
    "height": "196.667px",
    "left": "921px",
    "right": "20px",
    "top": "85px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
